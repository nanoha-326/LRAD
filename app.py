import streamlit as st
import pandas as pd
import numpy as np
import datetime
import re
import unicodedata
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¢ãƒ—ãƒªè¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ",
                   page_icon="ğŸ“˜",
                   layout="centered")

client = OpenAI(api_key=st.secrets.OpenAIAPI.openai_api_key)

system_prompt = """
ã‚ãªãŸã¯LRADå°‚ç”¨ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚
ã€ŒLRADï¼ˆã‚¨ãƒ«ãƒ©ãƒ‰ï¼‰ã€ã¨ã¯ç†±åˆ†è§£è£…ç½®ï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®ã“ã¨ã§ã€ã“ã‚Œã¯æœ‰æ©Ÿå»ƒæ£„ç‰©ã®å‡¦ç†è£…ç½®ã§ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€ã“ã®è£…ç½®ã®æ¤œè¨¼ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã™ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’å®ˆã£ã¦ãã ã•ã„ï¼š
ãƒ»è£…ç½®ã«é–¢é€£ã™ã‚‹ã“ã¨ã®ã¿ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚
ãƒ»é–¢ä¿‚ãªã„è©±é¡Œï¼ˆå¤©æ°—ã€èŠ¸èƒ½ã€ã‚¹ãƒãƒ¼ãƒ„ãªã©ï¼‰ã«ã¯ç­”ãˆãªã„ã§ãã ã•ã„ã€‚
ãƒ»FAQã«ãªã„å ´åˆã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def is_valid_input(text: str) -> bool:
    text = text.strip()
    if len(text) < 3 or len(text) > 300:
        return False
    non_alpha_ratio = len(
        re.findall(r'[^A-Za-z0-9ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ \s]', text)) / len(text)
    if non_alpha_ratio > 0.3:
        return False
    try:
        unicodedata.normalize('NFKC', text).encode('utf-8')
    except UnicodeError:
        return False
    return True


def get_embedding(text):
    """list ã§è¿”ã™ï¼ˆnp.array ã«ã—ãªã„ï¼‰"""
    response = client.embeddings.create(
        input=[text],
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding


@st.cache_data(show_spinner=False)
def load_faq(csv_file):
    df = pd.read_csv(csv_file)
    df["embedding"] = df["è³ªå•"].apply(get_embedding)
    return df


faq_df = load_faq("faq.csv")
faq_questions = faq_df["è³ªå•"].tolist()      # â˜… ã‚µã‚¸ã‚§ã‚¹ãƒˆç”¨ã«ãƒªã‚¹ãƒˆåŒ–

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FAQ é¡ä¼¼è³ªå•æ¤œç´¢ & GPT ç”Ÿæˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_similar_question(user_input):
    user_vec = get_embedding(user_input)
    faq_vecs = np.array(faq_df["embedding"].tolist())
    scores = cosine_similarity([user_vec], faq_vecs)[0]
    top_idx = scores.argmax()
    return faq_df.iloc[top_idx]["è³ªå•"], faq_df.iloc[top_idx]["å›ç­”"]


def generate_response(context_q, context_a, user_input):
    prompt = (
        "ä»¥ä¸‹ã¯FAQã«åŸºã¥ã„ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä¼šè©±ã§ã™ã€‚\n\n"
        f"è³ªå•: {context_q}\nå›ç­”: {context_a}\n\n"
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_input}\n\n"
        "ã“ã‚Œã‚’å‚è€ƒã«ã€ä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ãè‡ªç„¶ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚"
    )
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
        ],
        temperature=1.2,
    )
    return response.choices[0].message.content


def save_log(log_data):
    now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"chatlog_{now}.csv"
    pd.DataFrame(log_data,
                 columns=["ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•", "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å›ç­”"]
                 ).to_csv(filename, index=False, encoding="utf-8-sig")
    return filename


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¿ã‚¤ãƒˆãƒ« & ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºè¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ")
st.caption(
    "â€»ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯FAQã¨AIã‚’ã‚‚ã¨ã«å¿œç­”ã—ã¾ã™ãŒã€ã™ã¹ã¦ã®è³ªå•ã«æ­£ç¢ºã«å›ç­”ã§ãã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚")

with st.sidebar:
    st.header("âš™ï¸ è¡¨ç¤ºè¨­å®š")
    size_option = st.radio("æ–‡å­—ã‚µã‚¤ã‚ºã‚’é¸æŠ", ["å°", "ä¸­", "å¤§"],
                           index=1, horizontal=False)

size_map = {"å°": 14, "ä¸­": 18, "å¤§": 24}
font_px = size_map[size_option]

st.markdown(
    f"""
    <style>
    div.stChatMessage p {{
        font-size: {font_px}px !important;
    }}
    input[type="text"], button {{
        font-size: {font_px}px !important;
    }}
    </style>
    """,
    unsafe_allow_html=True,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []
if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â˜…â˜…â˜… ã“ã“ã‹ã‚‰ï¼šå…¥åŠ›ã‚µã‚¸ã‚§ã‚¹ãƒˆæ©Ÿèƒ½ â˜…â˜…â˜…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
current_text = st.session_state.user_input
if current_text:
    # éƒ¨åˆ†ä¸€è‡´ã§å€™è£œæŠ½å‡ºï¼ˆé‡è¤‡é™¤å»ï¼†æœ€å¤§ 5 ä»¶ï¼‰
    suggestions = [
        q for q in faq_questions
        if current_text.lower() in q.lower() and q != current_text
    ][:5]
else:
    suggestions = []

if suggestions:
    st.markdown("#### ğŸ” é–¢é€£ã™ã‚‹ã‚ˆãã‚ã‚‹è³ªå•å€™è£œ")
    for i, s in enumerate(suggestions):
        if st.button(s, key=f"suggest_{i}"):
            # å€™è£œã‚’ã‚¯ãƒªãƒƒã‚¯ â†’ å…¥åŠ›æ¬„ã«ã‚»ãƒƒãƒˆã—ã¦å³å†æç”»
            st.session_state.user_input = s
            st.experimental_rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.form(key="chat_form", clear_on_submit=True):
    user_input = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š",
                               key="user_input",
                               placeholder="ä¾‹ï¼šå‡¦ç†æ¸©åº¦ã¯ä½•â„ƒã§ã™ã‹ï¼Ÿ")
    submitted = st.form_submit_button("é€ä¿¡")

    if submitted and user_input:
        if not is_valid_input(user_input):
            st.session_state.chat_log.insert(
                0, (user_input, "ã‚¨ãƒ©ãƒ¼ï¼šå…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚"))
            st.experimental_rerun()

        similar_q, similar_a = find_similar_question(user_input)
        with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦ãŠå¾…ã¡ãã ã•ã„ã€‚"):
            answer = generate_response(similar_q, similar_a, user_input)

        st.session_state.chat_log.insert(0, (user_input, answer))
        st.session_state.user_input = ""  # é€ä¿¡å¾Œã¯å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢
        st.experimental_rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for user_msg, bot_msg in st.session_state.chat_log:
    with st.chat_message("user"):
        st.markdown(user_msg)
    with st.chat_message("assistant"):
        st.markdown(bot_msg)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ä¿å­˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜"):
    filename = save_log(st.session_state.chat_log)
    st.success(f"ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
    with open(filename, "rb") as f:
        st.download_button("ã“ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                           data=f,
                           file_name=filename,
                           mime="text/csv")
