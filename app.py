import streamlit as st
import openai
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os
import random

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ", layout="centered")

# --- APIã‚­ãƒ¼ ---
openai.api_key = st.secrets.OpenAIAPI.openai_api_key 

# --- åŸ‹ã‚è¾¼ã¿å–å¾—é–¢æ•° ---
def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    response = openai.embeddings.create(input=[text], model=model)
    return np.array(response.data[0].embedding)

# --- å…¨è³ªå•ç”¨FAQèª­ã¿è¾¼ã¿ï¼ˆå›ç­”æ¤œç´¢ç”¨ï¼‰ ---
@st.cache_data
def load_faq_all(csv_file):
    df = pd.read_csv(csv_file)
    df['embedding'] = df['è³ªå•'].apply(lambda x: get_embedding(x))
    return df

# --- ã‚ˆãã‚ã‚‹è³ªå•ç”¨FAQèª­ã¿è¾¼ã¿ï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¡¨ç¤ºç”¨ï¼‰ ---
@st.cache_data
def load_faq_common(csv_file):
    df = pd.read_csv(csv_file)
    return df

faq_df = load_faq_all("faq_all.csv")         # å…¨FAQï¼ˆembeddingä»˜ãï¼‰
common_faq_df = load_faq_common("faq_common.csv")  # ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆembeddingãªã—ï¼‰

# --- ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚ˆãã‚ã‚‹è³ªå•3ä»¶ã‚’è¡¨ç¤º ---
def display_random_common_faqs(common_faq_df, n=3):
    sampled = common_faq_df.sample(n)
    st.markdown("### ã‚ˆãã‚ã‚‹è³ªå•ã®ä¾‹")
    for i, row in enumerate(sampled.itertuples(), 1):
        st.markdown(f"**{i}. {row.è³ªå•}**")
        st.markdown(f"å›ç­”: {row.å›ç­”}")
        st.markdown("---")

# --- é¡ä¼¼è³ªå•æ¤œç´¢ ---
def find_top_similar_questions(user_input, faq_df, top_n=5):
    if len(user_input.strip()) < 2:
        return []
    user_vec = get_embedding(user_input)
    faq_vecs = np.stack(faq_df['embedding'].to_numpy())
    scores = cosine_similarity([user_vec], faq_vecs)[0]
    top_indices = scores.argsort()[::-1][:top_n]
    return faq_df.iloc[top_indices][['è³ªå•', 'å›ç­”']].values.tolist()

# --- å›ç­”ç”Ÿæˆ ---
def generate_response(user_input, matched_answer, matched_question):
    prompt = f"""ã‚ãªãŸã¯LRADï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚
æ¬¡ã®FAQã¨ç…§ã‚‰ã—åˆã‚ã›ã¦ã€200æ–‡å­—ä»¥å†…ã§è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

è³ªå•: {user_input}
æœ€ã‚‚è¿‘ã„FAQ: {matched_question}
å›ç­”: {matched_answer}
"""
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# --- UI ---
st.title("ğŸ¤– LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ")

# å…¥åŠ›æ¬„ï¼ˆå³æ™‚åå¿œï¼‰
user_input = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š", value=st.session_state.user_input, key="user_input")

# --- æ—¢å­˜ã®ãƒ•ã‚©ãƒ¼ãƒ ã®ç›´å‰ã«ãƒ©ãƒ³ãƒ€ãƒ FAQè¡¨ç¤ºã‚’å…¥ã‚Œã‚‹ä¾‹ ---
display_random_common_faqs(common_faq_df, n=3)

with st.form(key="chat_form", clear_on_submit=True):
    user_input = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š", key="user_input")
    submitted = st.form_submit_button("é€ä¿¡")

    if submitted and user_input:
        if not is_valid_input(user_input):
            st.session_state.chat_log.insert(0, (user_input, "ã‚¨ãƒ©ãƒ¼ï¼šå…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚"))
            st.experimental_rerun()
        similar_q, similar_a = find_similar_question(user_input, faq_df)
        with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦ãŠå¾…ã¡ãã ã•ã„ã€‚"):
            answer = generate_response(similar_q, similar_a, user_input)
        st.session_state.chat_log.insert(0, (user_input, answer))
        st.experimental_rerun()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
st.subheader("ğŸ“œ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
for q, a in st.session_state.chat_log:
    st.markdown(f"**ğŸ§‘â€ğŸ’» è³ªå•:** {q}")
    st.markdown(f"**ğŸ¤– å›ç­”:** {a}")
    st.markdown("---")
