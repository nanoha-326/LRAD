import streamlit as st
import pandas as pd
import openai
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import datetime
import re
import unicodedata

# ---------- Streamlit ã®è¨­å®š ----------
st.set_page_config(
    page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ",
    page_icon="ğŸ“˜",
    layout="centered"
)

# ---------- CSSï¼ˆãƒãƒ£ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å›ºå®šã¨ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢ä½™ç™½èª¿æ•´ï¼‰ ----------
st.markdown("""
<style>
body { background-color:#f6f6f6; }

.chat-container {
    max-width: 700px;
    margin: 0 auto;
    padding: 10px;
    padding-bottom: 140px;  /* ãƒ•ã‚©ãƒ¼ãƒ ã®é«˜ã•åˆ†ã®ä½™ç™½ã‚’ç¢ºä¿ */
}

.user-message {
    background:#dcf8c6;
    border-radius:20px 20px 0 20px;
    margin:10px 0 10px 40px;
    padding:12px 15px;
    max-width:75%;
    font-size:16px;
    word-break:break-word;
    box-shadow:0 1px 1px rgba(0,0,0,.1);
}
.bot-message {
    background:#fff;
    border-radius:20px 20px 20px 0;
    margin:10px 40px 10px 0;
    padding:12px 15px;
    max-width:75%;
    font-size:16px;
    word-break:break-word;
    box-shadow:0 1px 1px rgba(0,0,0,.1);
}

/* ãƒãƒ£ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å›ºå®š */
.chat-form-container {
    position: fixed;
    bottom: 0;
    left: 0;
    width: 100%;
    background: #f6f6f6;
    padding: 10px 20px;
    box-shadow: 0 -2px 5px rgba(0,0,0,0.1);
    z-index: 9999;
}

/* å…¥åŠ›æ¬„ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºèª¿æ•´ */
.stTextInput > div > input {
    font-size: 16px;
}
</style>
""", unsafe_allow_html=True)

# ---------- OpenAI API ã‚­ãƒ¼ ----------
openai.api_key = st.secrets.OpenAIAPI.openai_api_key

# ---------- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ« ----------
model = SentenceTransformer("all-MiniLM-L6-v2")

# ---------- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ----------
system_prompt = """
ã‚ãªãŸã¯LRADå°‚ç”¨ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚
ã€ŒLRADï¼ˆã‚¨ãƒ«ãƒ©ãƒ‰ï¼‰ã€ã¨ã¯ç†±åˆ†è§£è£…ç½®ï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®ã“ã¨ã§ã€ã“ã‚Œã¯æœ‰æ©Ÿå»ƒæ£„ç‰©ã®å‡¦ç†è£…ç½®ã§ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€ã“ã®è£…ç½®ã®æ¤œè¨¼ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã™ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’å®ˆã£ã¦ãã ã•ã„ï¼š
ãƒ»ã‚ãªãŸã¯LRADã®å°‚é–€å®¶ã¨ã—ã¦åˆ©ç”¨è€…ã®è³ªå•ã«ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã€å‡¦ç†æ¤œè¨¼ã‚’ã‚µãƒãƒ¼ãƒˆã§ãã¾ã™ã€‚
ãƒ»è£…ç½®ã«é–¢é€£ã™ã‚‹ã“ã¨ã®ã¿ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚ãã‚Œä»¥å¤–ã®è³ªå•ï¼ˆä¾‹ï¼šå¤©æ°—ã€æœ‰åäººã€è¶£å‘³ã€æ€æƒ³ã€æ–™ç†ã€æ”¿æ²»ã€ã‚²ãƒ¼ãƒ ã€ã‚¹ãƒãƒ¼ãƒ„ã€å¥åº·ãªã©ï¼‰ã«ã¯çµ¶å¯¾ã«ç­”ãˆãªã„ã§ãã ã•ã„ã€‚
ãƒ»ä¸–é–“è©±ã‚’ã•ã‚Œã¦ã‚‚LRADã«é–¢ä¿‚ã®ãªã„å ´åˆã¯ç­”ãˆãªã„ã§ãã ã•ã„ã€‚
ãƒ»è³ªå•ã«ã¯è¦ªåˆ‡ã«ã€ã§ãã‚‹ã ã‘åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚
ãƒ»FAQã®ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«é¡ä¼¼ã™ã‚‹æƒ…å ±ãŒãªã„å ´åˆã¯ã€å›ç­”ãŒä¸æ˜ã§ã‚ã‚‹ã“ã¨ã‚’ä¸å¯§ã«ä¼ãˆã€é©åˆ‡ã«å¯¾å¿œã—ã¦ãã ã•ã„ã€‚
"""

# ---------- å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ ----------
def is_valid_input(text: str) -> bool:
    text = text.strip()
    if len(text) < 3 or len(text) > 300:
        return False
    non_alpha_ratio = len(re.findall(r"[^A-Za-z0-9ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ \s]", text)) / len(text)
    if non_alpha_ratio > 0.3:
        return False
    try:
        unicodedata.normalize("NFKC", text).encode("utf-8")
    except UnicodeError:
        return False
    return True


# ---------- FAQ èª­ã¿è¾¼ã¿ ----------
@st.cache_data(show_spinner="FAQ èª­ã¿è¾¼ã¿ä¸­â€¦")
def load_faq(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df["embedding"] = df["è³ªå•"].apply(lambda x: model.encode(x))
    return df

faq_df = load_faq("faq.csv")


# ---------- é¡ä¼¼è³ªå•æ¤œç´¢ ----------
def find_similar_question(query: str):
    user_vec = model.encode([query])
    faq_vecs = list(faq_df["embedding"])
    scores = cosine_similarity(user_vec, faq_vecs)[0]
    top_idx = scores.argmax()
    return faq_df.iloc[top_idx]["è³ªå•"], faq_df.iloc[top_idx]["å›ç­”"]


# ---------- GPT ã§å›ç­”ç”Ÿæˆ ----------
def generate_response(context_q: str, context_a: str, user_input: str) -> str:
    prompt = (
        "ä»¥ä¸‹ã¯FAQã«åŸºã¥ã„ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä¼šè©±ã§ã™ã€‚\n\n"
        f"è³ªå•: {context_q}\nå›ç­”: {context_a}\n\n"
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_input}\n\n"
        "ã“ã‚Œã‚’å‚è€ƒã«ã€ä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ãè‡ªç„¶ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚"
    )
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
        ],
        temperature=1.5,
    )
    answer = response.choices[0].message.content


# ---------- ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ä¿å­˜ ----------
def save_log(log):
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    fname = f"chatlog_{ts}.csv"
    pd.DataFrame(log, columns=["ãƒ¦ãƒ¼ã‚¶ãƒ¼", "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ"]).to_csv(fname, index=False)
    return fname


# ---------- UI ----------
st.title("LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ")
st.caption("â€»FAQã¨GPTã‚’ç”¨ã„ã¦å›ç­”ã—ã¾ã™ã€‚å†…å®¹ã®æ­£ç¢ºæ€§ã¯ä¿è¨¼ã•ã‚Œã¾ã›ã‚“ã€‚")

if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆçœç•¥å¯ï¼‰
with st.sidebar:
    st.markdown("### âš™ï¸ è¡¨ç¤ºè¨­å®š")
    font_size = st.radio("æ–‡å­—ã‚µã‚¤ã‚º", ["å°", "æ¨™æº–", "å¤§"], index=1)
    st.divider()
    st.markdown("èƒŒæ™¯è‰²ãƒ†ãƒ¼ãƒç­‰ã‚’è¿½åŠ äºˆå®š")

# ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°è¡¨ç¤º
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

for u, a in st.session_state.chat_log:
    st.markdown(f'<div class="user-message">{u}</div>', unsafe_allow_html=True)
    st.markdown(f'<div class="bot-message">{a}</div>', unsafe_allow_html=True)

st.markdown("</div>", unsafe_allow_html=True)

# ãƒãƒ£ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å›ºå®šéƒ¨åˆ†
st.markdown('<div class="chat-form-container">', unsafe_allow_html=True)

with st.form(key="chat_form", clear_on_submit=True):
    user_input = st.text_input("", placeholder="è³ªå•ã‚’ã©ã†ã")
    submitted = st.form_submit_button("é€ä¿¡")

    if submitted and user_input:
        if not is_valid_input(user_input):
            st.session_state.chat_log.append(
                (user_input, "å…¥åŠ›ã‚¨ãƒ©ãƒ¼ï¼š3ã€œ300æ–‡å­—ã§ã€è¨˜å·ã‚’å¤šç”¨ã—ãªã„ã§ãã ã•ã„ã€‚")
            )
            st.experimental_rerun()

        similar_q, similar_a = find_similar_question(user_input)
        answer = generate_response(similar_q, similar_a, user_input)
        st.session_state.chat_log.append((user_input, answer))
        st.experimental_rerun()

st.markdown('</div>', unsafe_allow_html=True)

# ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ä¿å­˜ãƒœã‚¿ãƒ³
if st.button("ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜"):
    fname = save_log(st.session_state.chat_log)
    st.success(f"ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼š{fname}")
    with open(fname, "rb") as f:
        st.download_button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=f, file_name=fname, mime="text/csv")
