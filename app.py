import streamlit as st
import openai
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ", layout="centered")

# --- APIã‚­ãƒ¼ ---
openai.api_key = st.secrets.OpenAIAPI.openai_api_key 

# --- åŸ‹ã‚è¾¼ã¿å–å¾—é–¢æ•° ---
def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    response = openai.embeddings.create(input=[text], model=model)
    return np.array(response.data[0].embedding)

# --- FAQèª­ã¿è¾¼ã¿ï¼ˆåŸ‹ã‚è¾¼ã¿ä»˜ãï¼‰ ---
@st.cache_data
def load_faq(path="faq.csv", embed_path="faq_with_embeddings.csv"):
    if os.path.exists(embed_path):
        df = pd.read_csv(embed_path)
        df['embedding'] = df['embedding'].apply(eval).apply(np.array)
    else:
        df = pd.read_csv(path)
        with st.spinner("FAQã«embeddingã‚’ä»˜ä¸ä¸­...ï¼ˆåˆå›ã®ã¿ï¼‰"):
            df["embedding"] = df["è³ªå•"].apply(get_embedding)
        df.to_csv(embed_path, index=False)
    return df

faq_df = load_faq()

# --- é¡ä¼¼è³ªå•æ¤œç´¢ ---
def find_top_similar_questions(user_input, faq_df, top_n=5):
    if len(user_input.strip()) < 2:
        return []
    user_vec = get_embedding(user_input)
    faq_vecs = np.stack(faq_df['embedding'].to_numpy())
    scores = cosine_similarity([user_vec], faq_vecs)[0]
    top_indices = scores.argsort()[::-1][:top_n]
    return faq_df.iloc[top_indices][['è³ªå•', 'å›ç­”']].values.tolist()

# --- å›ç­”ç”Ÿæˆ ---
def generate_response(user_input, matched_answer, matched_question):
    prompt = f"""ã‚ãªãŸã¯LRADï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚
æ¬¡ã®FAQã¨ç…§ã‚‰ã—åˆã‚ã›ã¦ã€200æ–‡å­—ä»¥å†…ã§è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

è³ªå•: {user_input}
æœ€ã‚‚è¿‘ã„FAQ: {matched_question}
å›ç­”: {matched_answer}
"""
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# --- UI ---
st.title("ğŸ¤– LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ")

# å…¥åŠ›æ¬„ï¼ˆå³æ™‚åå¿œï¼‰
user_input = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š", value=st.session_state.user_input, key="user_input")

# é¡ä¼¼è³ªå•ã®å³æ™‚è¡¨ç¤º
if user_input:
    st.subheader("ğŸ” å…¥åŠ›ã«åŸºã¥ããŠã™ã™ã‚ã®è³ªå•")
    suggested_qas = find_top_similar_questions(user_input, faq_df)
    for i, (q, a) in enumerate(suggested_qas):
        # ãƒœã‚¿ãƒ³æŠ¼ä¸‹ã§å›ç­”ç”Ÿæˆãƒ»ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°è¿½åŠ ãƒ»ç”»é¢å†èª­ã¿è¾¼ã¿
        if st.button(f"{i+1}. {q}"):
            with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦ãŠå¾…ã¡ãã ã•ã„ã€‚"):
                answer = generate_response(q, a, q)
            st.session_state.chat_log.insert(0, (q, answer))
            st.session_state.user_input = ""  # å…¥åŠ›æ¬„ã‚¯ãƒªã‚¢
            st.experimental_rerun()

# é€ä¿¡ãƒœã‚¿ãƒ³ã§ç›´æ¥è³ªå•é€ä¿¡
if st.button("é€ä¿¡") and user_input.strip():
    with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦ãŠå¾…ã¡ãã ã•ã„ã€‚"):
        suggested_qas = find_top_similar_questions(user_input, faq_df, top_n=1)
        if suggested_qas:
            matched_q, matched_a = suggested_qas[0]
        else:
            matched_q, matched_a = "è©²å½“ãªã—", "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€è©²å½“ã™ã‚‹FAQãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        answer = generate_response(user_input, matched_a, matched_q)
    st.session_state.chat_log.insert(0, (user_input, answer))
    st.session_state.user_input = ""  # å…¥åŠ›æ¬„ã‚¯ãƒªã‚¢
    st.experimental_rerun()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
st.subheader("ğŸ“œ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
for q, a in st.session_state.chat_log:
    st.markdown(f"**ğŸ§‘â€ğŸ’» è³ªå•:** {q}")
    st.markdown(f"**ğŸ¤– å›ç­”:** {a}")
    st.markdown("---")
