import streamlit as st
import openai
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os, random, re, unicodedata

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒšãƒ¼ã‚¸è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ", layout="centered")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAIã‚­ãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai.api_key = st.secrets.OpenAIAPI.openai_api_key

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    res = openai.embeddings.create(input=[text], model=model)
    return np.array(res.data[0].embedding)

def is_valid_input(text: str) -> bool:
    text = text.strip()
    if not (3 <= len(text) <= 300):
        return False
    if len(re.findall(r'[^A-Za-z0-9ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ \s]', text)) / len(text) > 0.3:
        return False
    try:
        unicodedata.normalize("NFKC", text).encode("utf-8")
    except UnicodeError:
        return False
    return True

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CSVèª­è¾¼ã¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def load_faq_all(path="faq_all.csv", cached="faq_all_with_embed.csv"):
    if os.path.exists(cached):
        df = pd.read_csv(cached)
        df["embedding"] = df["embedding"].apply(eval).apply(np.array)
    else:
        df = pd.read_csv(path)
        with st.spinner("å…¨FAQã¸åŸ‹ã‚è¾¼ã¿è¨ˆç®—ä¸­â€¦ï¼ˆåˆå›ã®ã¿ï¼‰"):
            df["embedding"] = df["è³ªå•"].apply(get_embedding)
        df.to_csv(cached, index=False)
    return df

@st.cache_data(show_spinner=False)
def load_faq_common(path="faq_common.csv"):
    return pd.read_csv(path)

faq_df = load_faq_all()
common_faq_df = load_faq_common()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ©ãƒ³ãƒ€ãƒ FAQè¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def show_random_faq(df, n=3):
    n = min(n, len(df))
    for i, row in df.sample(n).itertuples(index=False, name=None):
        st.markdown(f"**â“ {row[0]}**")  # row[0] = è³ªå•
        st.markdown(f"ğŸ…°ï¸ {row[1]}")
        st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é¡ä¼¼è³ªå•æ¤œç´¢
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_top_similar(q, df, k=1):
    if len(q.strip()) < 2:
        return None, None
    q_vec = get_embedding(q)
    faq_vecs = np.stack(df["embedding"].to_numpy())
    sims = cosine_similarity([q_vec], faq_vecs)[0]
    idx = sims.argsort()[::-1][:k][0]
    return df.iloc[idx]["è³ªå•"], df.iloc[idx]["å›ç­”"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å›ç­”ç”Ÿæˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_response(user_q, ref_q, ref_a):
    prompt = (
        "ã‚ãªãŸã¯LRADï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚\n"
        "ä»¥ä¸‹ã®FAQã‚’å‚è€ƒã«200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
        f"FAQè³ªå•: {ref_q}\nFAQå›ç­”: {ref_a}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {user_q}"
    )
    res = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
    )
    return res.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UIæç”»
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ¤– LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ")

# ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆCSVâ‘¡ ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ï¼‰
st.markdown("### ğŸ’¡ ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¡¨ç¤ºï¼‰")
show_random_faq(common_faq_df, n=3)

st.divider()

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form(key="chat_form", clear_on_submit=True):
    user_q = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š")
    send = st.form_submit_button("é€ä¿¡")

if send and user_q:
    if not is_valid_input(user_q):
        st.warning("å…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚3ã€œ300æ–‡å­—ã€è¨˜å·ç‡30%æœªæº€ã«ã—ã¦ãã ã•ã„ã€‚")
    else:
        ref_q, ref_a = find_top_similar(user_q, faq_df)
        if ref_q is None:
            answer = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€é–¢é€£FAQãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        else:
            with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦"):
                answer = generate_response(user_q, ref_q, ref_a)
        st.session_state.chat_log.insert(0, (user_q, answer))
        st.experimental_rerun()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´
if st.session_state.chat_log:
    st.subheader("ğŸ“œ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
    for q, a in st.session_state.chat_log:
        st.markdown(f"**ğŸ§‘â€ğŸ’» è³ªå•:** {q}")
        st.markdown(f"**ğŸ¤– å›ç­”:** {a}")
        st.markdown("---")
