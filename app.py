import streamlit as st
import openai
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os

# --- API KEY ---
openai.api_key = st.secrets.OpenAIAPI.openai_api_key 

# --- OpenAI åŸ‹ã‚è¾¼ã¿å–å¾— ---
def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    response = openai.embeddings.create(input=[text], model=model)
    return np.array(response.data[0].embedding)

# --- FAQ èª­ã¿è¾¼ã¿ï¼ˆåŸ‹ã‚è¾¼ã¿è‡ªå‹•ä»˜ä¸ï¼‰ ---
@st.cache_data
def load_faq(path="faq.csv", embed_path="faq_with_embeddings.csv"):
    if os.path.exists(embed_path):
        df = pd.read_csv(embed_path)
        df['embedding'] = df['embedding'].apply(eval).apply(np.array)
    else:
        df = pd.read_csv(path)
        with st.spinner("FAQã«embeddingã‚’ä»˜ä¸ä¸­...ï¼ˆåˆå›ã®ã¿ï¼‰"):
            df["embedding"] = df["è³ªå•"].apply(get_embedding)
        df.to_csv(embed_path, index=False)
    return df

faq_df = load_faq()

# --- é¡ä¼¼è³ªå•ã‚’æ¤œç´¢ ---
def find_top_similar_questions(user_input, faq_df, top_n=5):
    if len(user_input.strip()) < 2:
        return []
    user_vec = get_embedding(user_input)
    faq_vecs = np.stack(faq_df['embedding'].to_numpy())
    scores = cosine_similarity([user_vec], faq_vecs)[0]
    top_indices = scores.argsort()[::-1][:top_n]
    return faq_df.iloc[top_indices][['è³ªå•', 'å›ç­”']].values.tolist()

# --- å›ç­”ç”Ÿæˆ ---
def generate_response(user_input, matched_answer, matched_question):
    prompt = f"""ã‚ãªãŸã¯LRADï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚
æ¬¡ã®FAQã¨ç…§ã‚‰ã—åˆã‚ã›ã¦ã€200æ–‡å­—ä»¥å†…ã§è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

è³ªå•: {user_input}
æœ€ã‚‚è¿‘ã„FAQ: {matched_question}
å›ç­”: {matched_answer}
"""
    response = openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# --- UI ---
st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ", layout="centered")
st.title("ğŸ¤– LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ")

if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# --- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
with st.form(key="chat_form", clear_on_submit=True):
    user_input = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š", key="user_input")
    submitted = st.form_submit_button("é€ä¿¡")

# --- æ¤œç´¢å€™è£œè¡¨ç¤º ---
if user_input:
    st.subheader("ğŸ” å…¥åŠ›ã«åŸºã¥ããŠã™ã™ã‚ã®è³ªå•")

    suggested_qas = find_top_similar_questions(user_input, faq_df)
    for i, (q, a) in enumerate(suggested_qas):
        if st.button(f"{i+1}. {q}"):
            with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦ãŠå¾…ã¡ãã ã•ã„ã€‚"):
                answer = generate_response(q, a, q)
            st.session_state.chat_log.insert(0, (q, answer))
            st.rerun()

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸå ´åˆã®å‡¦ç† ---
if submitted and user_input:
    with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦ãŠå¾…ã¡ãã ã•ã„ã€‚"):
        suggested_qas = find_top_similar_questions(user_input, faq_df, top_n=1)
        if suggested_qas:
            matched_q, matched_a = suggested_qas[0]
        else:
            matched_q, matched_a = "è©²å½“ãªã—", "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€è©²å½“ã™ã‚‹FAQãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        answer = generate_response(user_input, matched_a, matched_q)
    st.session_state.chat_log.insert(0, (user_input, answer))
    st.session_state.user_input = ""

# --- ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°è¡¨ç¤º ---
st.subheader("ğŸ“œ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
for q, a in st.session_state.chat_log:
    st.markdown(f"**ğŸ§‘â€ğŸ’» è³ªå•:** {q}")
    st.markdown(f"**ğŸ¤– å›ç­”:** {a}")
    st.markdown("---")
