import streamlit as st
from openai import OpenAI
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os, random, re, unicodedata, json
import base64

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ", layout="centered")

# OpenAIã‚­ãƒ¼
client = OpenAI(api_key=st.secrets.OpenAIAPI.openai_api_key)

# CSSæ³¨å…¥
def inject_custom_css(selected_size):
    st.markdown(
        f"""
        <style>
        .chat-text, .stCaption, .css-ffhzg2 p, .stTextInput > label {{
            font-size: {selected_size} !important;
        }}
        .stTextInput > div > div > input {{
            font-size: {selected_size} !important;
        }}
        ::placeholder {{
            font-size: {selected_size} !important;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

# Embeddingå–å¾—
def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    res = client.embeddings.create(input=[text], model=model)
    return res.data[0].embedding

# å…¥åŠ›ãƒã‚§ãƒƒã‚¯
def is_valid_input(text: str) -> bool:
    text = text.strip()
    if not (3 <= len(text) <= 300):
        return False
    if len(re.findall(r'[^A-Za-z0-9ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ \s]', text)) / len(text) > 0.3:
        return False
    try:
        unicodedata.normalize("NFKC", text).encode("utf-8")
    except UnicodeError:
        return False
    return True

# CSVèª­ã¿è¾¼ã¿
@st.cache_data(show_spinner=False)
def load_faq_all(path="faq_all.csv", cached="faq_all_with_embed.csv"):
    if os.path.exists(cached):
        df = pd.read_csv(cached)
        try:
            df["embedding"] = df["embedding"].apply(json.loads).apply(np.array)
        except Exception as e:
            st.error(f"åŸ‹ã‚è¾¼ã¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()
    else:
        df = pd.read_csv(path)
        with st.spinner("å…¨FAQã¸åŸ‹ã‚è¾¼ã¿è¨ˆç®—ä¸­â€¦ï¼ˆåˆå›ã®ã¿ï¼‰"):
            df["embedding"] = df["è³ªå•"].apply(get_embedding)
        # æ–‡å­—åˆ—åŒ–ã—ã¦ä¿å­˜
        df["embedding"] = df["embedding"].apply(lambda x: json.dumps(x.tolist()))
        df.to_csv(cached, index=False)
        # èª­ã¿è¾¼ã¿ç›´ã—
        df["embedding"] = df["embedding"].apply(json.loads).apply(np.array)
    return df

@st.cache_data(show_spinner=False)
def load_faq_common(path="faq_common.csv"):
    df = pd.read_csv(path, encoding="utf-8-sig")
    df.columns = df.columns.str.strip()
    return df

faq_df = load_faq_all()
common_faq_df = load_faq_common()

# FAQè¡¨ç¤º
def display_random_common_faqs(common_faq_df, n=3):
    sampled = common_faq_df.sample(n)
    for i, row in enumerate(sampled.itertuples(), 1):
        question = getattr(row, "è³ªå•", "ï¼ˆè³ªå•ãŒä¸æ˜ã§ã™ï¼‰")
        answer = getattr(row, "å›ç­”", "ï¼ˆå›ç­”ãŒä¸æ˜ã§ã™ï¼‰")
        st.markdown(
            f'<div class="chat-text"><b>â“ {question}</b><br>ğŸ…°ï¸ {answer}</div><hr>',
            unsafe_allow_html=True
        )

# é¡ä¼¼è³ªå•æ¤œç´¢
def find_top_similar(q, df, k=1):
    if len(q.strip()) < 2:
        return None, None
    q_vec = get_embedding(q)
    faq_vecs = np.stack(df["embedding"].to_numpy())
    sims = cosine_similarity([q_vec], faq_vecs)[0]
    idx = sims.argsort()[::-1][:k][0]
    return df.iloc[idx]["è³ªå•"], df.iloc[idx]["å›ç­”"]

# å›ç­”ç”Ÿæˆ
def generate_response(user_q, ref_q, ref_a):
    prompt = (
        "ã‚ãªãŸã¯LRADï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚\n"
        "ä»¥ä¸‹ã®FAQã‚’å‚è€ƒã«200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
        f"FAQè³ªå•: {ref_q}\nFAQå›ç­”: {ref_a}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•: {user_q}"
    )
    res = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
    )
    return res.choices[0].message.content.strip()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.title("âš™ï¸ è¡¨ç¤ºè¨­å®š")
font_size = st.sidebar.selectbox("æ–‡å­—ã‚µã‚¤ã‚ºã‚’é¸ã‚“ã§ãã ã•ã„", ["å°", "ä¸­", "å¤§"])
font_size_map = {"å°": "14px", "ä¸­": "18px", "å¤§": "24px"}
img_width_map = {"å°": 60, "ä¸­": 80, "å¤§": 110}

selected_font = font_size_map[font_size]
selected_img = img_width_map[font_size]

inject_custom_css(selected_font)

# ãƒ˜ãƒƒãƒ€ãƒ¼ç”»åƒ
def get_base64_image(path):
    with open(path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

image_base64 = get_base64_image("LRADimg.png")

st.markdown(
    f"""
    <div style="display:flex; align-items:center;" class="chat-header">
        <img src="data:image/png;base64,{image_base64}"
             width="80px" style="margin-right:10px;">
        <h1 style="margin:0; font-size:40px; font-weight:bold;">LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ</h1>
    </div>
    """,
    unsafe_allow_html=True
)

st.caption("â€»ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯FAQã¨AIã‚’ã‚‚ã¨ã«å¿œç­”ã—ã¾ã™ãŒã€ã™ã¹ã¦ã®è³ªå•ã«æ­£ç¢ºã«å›ç­”ã§ãã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚")

# ã‚ˆãã‚ã‚‹è³ªå•è¡¨ç¤º
st.markdown("### ğŸ’¡ ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¡¨ç¤ºï¼‰")
display_random_common_faqs(common_faq_df, n=3)

st.divider()

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form(key="chat_form", clear_on_submit=True):
    user_q = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š")
    send = st.form_submit_button("é€ä¿¡")

if send and user_q:
    if not is_valid_input(user_q):
        st.warning("å…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚3ã€œ300æ–‡å­—ã€è¨˜å·ç‡30%æœªæº€ã«ã—ã¦ãã ã•ã„ã€‚")
    else:
        ref_q, ref_a = find_top_similar(user_q, faq_df)
        if ref_q is None:
            answer = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€é–¢é€£FAQãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        else:
            with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦"):
                answer = generate_response(user_q, ref_q, ref_a)
        st.session_state.chat_log.insert(0, (user_q, answer))
        st.experimental_rerun()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
if st.session_state.chat_log:
    st.subheader("ğŸ“œ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
    for q, a in st.session_state.chat_log:
        st.markdown(
            f'<div class="chat-text"><b>ğŸ§‘â€ğŸ’» è³ªå•:</b> {q}<br><b>ğŸ¤– å›ç­”:</b> {a}</div><hr>',
            unsafe_allow_html=True
        )
